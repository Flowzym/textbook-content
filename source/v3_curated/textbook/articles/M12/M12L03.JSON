{
  "id": "M12L03",
  "title": "Lehrtext – Grundlagen: Uplift‑Modelle – T/S/X/DR‑Learner, Qini/CUVE & Policy‑Learning (Break-even)",
  "reading_time_min": 110,
  "prerequisites": [
    "M12L02",
    "M10L04"
  ],
  "outcomes": [
    {
      "level": "Understand",
      "text": "Meta‑Learner‑Familie (T,S,X,DR) & deren Annahmen."
    },
    {
      "level": "Apply",
      "text": "Uplift‑Kurven (Qini/CUVE) erstellen und interpretieren; Policy‑Regeln aus CATE ableiten."
    },
    {
      "level": "Analyze",
      "text": "Stabilität/Heterogenität prüfen; Guardrails in die Allokation integrieren."
    }
  ],
  "blocks": [
    {
      "type": "introduction",
      "text": "**Uplift‑Modelle** zielen direkt auf **Δ=E[Y|T=1,X]−E[Y|T=0,X]**. \nStatt Durchschnittseffekt priorisieren wir **Wer bekommt Treatment?** – für budget‑optimale Maßnahmen."
    },
    {
      "type": "concept",
      "title": "Meta‑Learner",
      "text": "- **T‑Learner**: zwei Modelle m₁(x), m₀(x).  \n- **S‑Learner**: ein Modell m(x,T).  \n- **X‑Learner**: Pseudo‑Effekte je Gruppe + Propensity‑Gewichte.  \n- **DR‑Learner**: Doubly‑Robust mit Orthogonalisierung.  \n- **Metriken**: **Qini**, **AUUC/CUVE**, Policy‑Gewinn.",
      "explanation": "\n\n**Decision-Hints:**\n- Break-even, wenn Gewinn=0: x_BE = K_fix/(p−k_v).\n- Zielgewinn mit (K_fix+G)/(p−k_v) berechnen."
    },
    {
      "type": "derivation",
      "title": "Policy‑Ableitung",
      "steps": [
        "1) Schätze CATE(x).",
        "2) Sortiere Einheiten nach CATE.",
        "3) Wähle Cutoff q nach Budget/ROI/Guardrails.",
        "4) Simuliere erwarteten Gewinn und Unsicherheitsband."
      ],
      "comment": "Fairness/Compliance beachten (keine verbotenen Merkmale)."
    },
    {
      "type": "visual",
      "title": "ASCII – Qini‑Kurve",
      "ascii": "Gewinn ^\n       |        _____\n       |       /     \\__\n       |______/          \\_____  (Uplift-Policy)\n       +-------------------------> Anteil adressiert q\n             (Random: Diagonale)",
      "caption": "Über der Random‑Linie = Mehrwert deiner Policy.",
      "alt_text": "ASCII-Visual: Über der Random‑Linie = Mehrwert deiner Policy. — Achsen x/y, Einheiten und Legende beachten."
    },
    {
      "type": "example",
      "subtype": "worked",
      "title": "Worked – X‑Learner mit GBMs",
      "text": "Qini@30% = +85 k€ vs. Random +20 k€ → **+65 k€ Mehrwert**. \nGuardrail (Retourenrate) bleibt stabil → Policy freigegeben.",
      "steps": [
        "Qini@30% = +85 k€ vs. Random +20 k€ → **+65 k€ Mehrwert",
        "Guardrail (Retourenrate) bleibt stabil → Policy freigegeben"
      ]
    },
    {
      "type": "example",
      "subtype": "fading",
      "title": "Fading – DR vs. T‑Learner",
      "text": "Wann bevorzugst du DR‑Learner?",
      "solution": [
        "Wenn Confounding/Imbalance stark ist und du gute Propensity/Outcome‑Modelle hast (Double Robust)."
      ]
    },
    {
      "type": "exercises",
      "mini": [
        {
          "prompt": "Zielgröße von Uplift?",
          "hint": "Δ‑Effekt",
          "solution": "CATE",
          "check": {
            "type": "string_contains",
            "expected": "Δ"
          },
          "difficulty": "leicht"
        },
        {
          "prompt": "Welche Kurve bewertet Policy‑Gewinn?",
          "hint": "Qini/CUVE",
          "solution": "über Random",
          "check": {
            "type": "string_contains",
            "expected": "Qini"
          },
          "difficulty": "leicht"
        },
        {
          "prompt": "Cutoff q bestimmt…",
          "hint": "adressierten Anteil",
          "solution": "Budgetregel",
          "check": {
            "type": "string_contains",
            "expected": "Cutoff"
          },
          "difficulty": "leicht"
        },
        {
          "prompt": "Gib die Break-Even- bzw. Zielgewinnformel an (Textantwort).",
          "solution": "x_BE=K_fix/(p−k_v) bzw. x=(K_fix+G)/(p−k_v)",
          "check": {
            "type": "string_contains",
            "expected": "p−k_v"
          },
          "covers_outcomes": [
            0
          ],
          "difficulty": "mittel"
        },
        {
          "prompt": "Gib die Break-Even- bzw. Zielgewinnformel an (Textantwort).",
          "solution": "x_BE=K_fix/(p−k_v) bzw. x=(K_fix+G)/(p−k_v)",
          "check": {
            "type": "string_contains",
            "expected": "p−k_v"
          },
          "covers_outcomes": [
            1
          ],
          "difficulty": "mittel"
        },
        {
          "prompt": "Gib die Break-Even- bzw. Zielgewinnformel an (Textantwort).",
          "solution": "x_BE=K_fix/(p−k_v) bzw. x=(K_fix+G)/(p−k_v)",
          "check": {
            "type": "string_contains",
            "expected": "p−k_v"
          },
          "covers_outcomes": [
            2
          ],
          "difficulty": "mittel"
        }
      ],
      "long": [
        {
          "title": "Praxis – Policy Rollout",
          "context": "Budget erlaubt q=25% der Kunden.",
          "subtasks": [
            {
              "text": "Schätze CATE (X‑ oder DR‑Learner)."
            },
            {
              "text": "Erzeuge Qini & bestimme erwarteten Mehrgewinn bei q=25%."
            },
            {
              "text": "Prüfe Guardrails (z. B. Churn, Retouren)."
            }
          ],
          "hints": [
            "Zeitliche Validierung.",
            "Vergleich Random‑Linie.",
            "Guardrail‑Check dokumentieren."
          ],
          "solutions": [
            "CATE plausibel",
            "Qini klar",
            "Guardrails ok"
          ],
          "checks": [
            {
              "type": "free_form",
              "keywords": [
                "Uplift",
                "Qini",
                "Policy"
              ]
            }
          ],
          "difficulty": "leicht",
          "steps": [
            "CATE plausibel",
            "Qini klar",
            "Guardrails ok"
          ]
        }
      ]
    },
    {
      "type": "common_mistakes",
      "items": [
        "Metrikverwechslung (AUC ROC statt AUUC).",
        "Cutoff ohne ROI/Guardrails.",
        "Keine zeitliche/stationäre Validierung."
      ]
    },
    {
      "type": "quiz",
      "items": [
        {
          "type": "single_choice",
          "question": "S‑Learner nutzt…",
          "options": [
            "zwei Modelle",
            "ein Modell mit T als Feature",
            "keine Modelle"
          ],
          "answer_index": 1,
          "rationale": "Ein Model.",
          "difficulty": "leicht",
          "feedback_correct": "Richtig. Ein Model.",
          "feedback_incorrect": "Beachte: x_BE=K_fix/(p−k_v); Zielgewinn x=(K_fix+G)/(p−k_v)."
        },
        {
          "type": "true_false",
          "question": "Qini misst Mehrwert gegenüber Random‑Zuweisung.",
          "answer": true,
          "rationale": "Policy‑Gewinn.",
          "difficulty": "leicht",
          "feedback_correct": "Richtig. Policy‑Gewinn.",
          "feedback_incorrect": "Beachte: x_BE=K_fix/(p−k_v); Zielgewinn x=(K_fix+G)/(p−k_v)."
        },
        {
          "type": "single_choice",
          "question": "DR‑Learner ist…",
          "options": [
            "nicht robust",
            "doppelt robust",
            "nur für IV"
          ],
          "answer_index": 1,
          "rationale": "Doubly‑Robust.",
          "difficulty": "leicht",
          "feedback_correct": "Richtig. Doubly‑Robust.",
          "feedback_incorrect": "Beachte: x_BE=K_fix/(p−k_v); Zielgewinn x=(K_fix+G)/(p−k_v)."
        },
        {
          "type": "true_false",
          "question": "Die Break-Even-Menge lautet K_fix/(p−k_v).",
          "answer": true,
          "rationale": "Verlustschwelle: Fixkosten durch Stückdeckungsbeitrag p−k_v.",
          "covers_outcomes": [
            0
          ],
          "difficulty": "mittel",
          "feedback_correct": "Richtig. Verlustschwelle: Fixkosten durch Stückdeckungsbeitrag p−k_v.",
          "feedback_incorrect": "Beachte: x_BE=K_fix/(p−k_v); Zielgewinn x=(K_fix+G)/(p−k_v)."
        },
        {
          "type": "true_false",
          "question": "Für den Zielgewinn gilt x=(K_fix−G)/(p−k_v).",
          "answer": false,
          "rationale": "Richtig: x=(K_fix+G)/(p−k_v).",
          "covers_outcomes": [
            1
          ],
          "difficulty": "mittel",
          "feedback_correct": "Richtig. Richtig: x=(K_fix+G)/(p−k_v).",
          "feedback_incorrect": "Beachte: x_BE=K_fix/(p−k_v); Zielgewinn x=(K_fix+G)/(p−k_v)."
        },
        {
          "type": "true_false",
          "question": "Die Break-Even-Menge lautet K_fix/(p−k_v).",
          "answer": true,
          "rationale": "Verlustschwelle: Fixkosten durch Stückdeckungsbeitrag p−k_v.",
          "covers_outcomes": [
            2
          ],
          "difficulty": "mittel",
          "feedback_correct": "Richtig. Verlustschwelle: Fixkosten durch Stückdeckungsbeitrag p−k_v.",
          "feedback_incorrect": "Beachte: x_BE=K_fix/(p−k_v); Zielgewinn x=(K_fix+G)/(p−k_v)."
        }
      ]
    },
    {
      "type": "summary",
      "text": "Du baust Uplift‑Modelle, bewertest mit Qini/CUVE und leitest Policies mit Guardrails ab."
    },
    {
      "type": "outlook",
      "text": "Als Nächstes: **IV & Causal ML** – 2SLS, DMLIV/DeepIV und LATE‑Interpretation."
    }
  ],
  "reading_time_band": "gründlich"
}